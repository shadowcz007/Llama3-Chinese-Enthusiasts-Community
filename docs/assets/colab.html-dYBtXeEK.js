import{_ as l,r as o,o as p,c as i,a as s,b as t,d as e,e as n}from"./app-E8nkCEVR.js";const r="/Llama3-Chinese-Enthusiasts-Community/assets/x1-BC3GzZXi.webp",m="/Llama3-Chinese-Enthusiasts-Community/assets/x2-CYGOxmgd.webp",h="/Llama3-Chinese-Enthusiasts-Community/assets/x3-B3VUxJXe.webp",c="/Llama3-Chinese-Enthusiasts-Community/assets/x4-vKvjg8B-.webp",u="/Llama3-Chinese-Enthusiasts-Community/assets/x5-Dm8KAfZl.webp",_="/Llama3-Chinese-Enthusiasts-Community/assets/x6-DqTaJLTc.webp",d="/Llama3-Chinese-Enthusiasts-Community/assets/x7-BQn_i0TC.webp",g="/Llama3-Chinese-Enthusiasts-Community/assets/x8-CfNmRVIF.webp",b="/Llama3-Chinese-Enthusiasts-Community/assets/x9-BjhxhVlL.webp",L="/Llama3-Chinese-Enthusiasts-Community/assets/x10-BjXLoxn_.webp",C="/Llama3-Chinese-Enthusiasts-Community/assets/x11-BDYY6BsO.webp",x="/Llama3-Chinese-Enthusiasts-Community/assets/x12-DQ-RU01B.webp",f="/Llama3-Chinese-Enthusiasts-Community/assets/x13-BYwvJ5Jq.webp",v="/Llama3-Chinese-Enthusiasts-Community/assets/x14-BmYEGeZ9.webp",y="/Llama3-Chinese-Enthusiasts-Community/assets/x15-DYshf5ZL.webp",w="/Llama3-Chinese-Enthusiasts-Community/assets/x16-CCSqOtEe.webp",E="/Llama3-Chinese-Enthusiasts-Community/assets/x17-DbGR7mN4.webp",G="/Llama3-Chinese-Enthusiasts-Community/assets/x18-ORmu1Toc.webp",k="/Llama3-Chinese-Enthusiasts-Community/assets/x19-CHX8FXbS.webp",q="/Llama3-Chinese-Enthusiasts-Community/assets/x20-DDn4AbgN.webp",T="/Llama3-Chinese-Enthusiasts-Community/assets/x21-eqMgXX33.webp",U="/Llama3-Chinese-Enthusiasts-Community/assets/x22-D9-zO9_m.webp",B="/Llama3-Chinese-Enthusiasts-Community/assets/x23-D_0Gq4Vp.webp",P="/Llama3-Chinese-Enthusiasts-Community/assets/x24-DjYrJFXX.webp",A="/Llama3-Chinese-Enthusiasts-Community/assets/x25-Btpoytcu.webp",D="/Llama3-Chinese-Enthusiasts-Community/assets/x26-C6rkEBSo.webp",M="/Llama3-Chinese-Enthusiasts-Community/assets/x27-FsPEkw1z.webp",R="/Llama3-Chinese-Enthusiasts-Community/assets/x28-CWvE0l3U.webp",F="/Llama3-Chinese-Enthusiasts-Community/assets/x29-CD1mNmI4.webp",I="/Llama3-Chinese-Enthusiasts-Community/assets/x30-BwQwndGF.webp",Q={},S=s("h1",{id:"llama3-微调教程-超简单-人人都可以打造属于自己的-gpt",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#llama3-微调教程-超简单-人人都可以打造属于自己的-gpt"},[s("span",null,"Llama3 微调教程：超简单，人人都可以打造属于自己的 GPT！")])],-1),V={href:"https://mp.weixin.qq.com/s/VV1BUMQIMrb5LxQNusQsDg",target:"_blank",rel:"noopener noreferrer"},N=n('<p>作者：PM 熊叔</p><p>随着 Llama 3 的发布，国内各路英雄豪杰纷纷开启了炼丹之旅。Llama-3 8b 在惊人的 15 万亿令牌上训练，而 Llama-2 仅为 2 万亿。毋庸置疑，Llama 3 目前是开源大模型中能力最强的！其跑分成绩已经赶上了 GPT-4。</p><p><img src="'+r+'" alt=""></p><p>然而，Llama 的优势不仅限于此。作为开源大模型，每个人都可以对其进行定制，这意味着相比 GPT，它具有更强的定制性和安全性。Llama 可应用于针对 B 端企业的自然语言处理、机器翻译、文本生成、问答系统、聊天机器人等场景。</p><p>目前，我们主要通过微调（Fine-Tuning）来定制所需的模型。例如，Llama 3 原生不支持中文，但我们可以通过微调让它支持中文。</p><p>微调是指在已经经过大规模预训练的基础模型上，使用特定领域或任务的数据集对模型进行额外训练，以适应特定任务或问题。微调过程通常包括在预训练模型的基础上进行少量迭代训练，以调整模型参数，使其在特定任务上表现更好。</p><p>通过这个简单的 Llama 3 微调案例，我们可以体验整个大模型微调的过程。对于普通人来说，这是一个免费体验算法工程师工作方式的机会；如果你想转入 AI 行业，这也是一个很好的入门案例。</p><p>愿每个人都能从中受益，开启自己的 AI 探索之旅！</p><p>接下来，你将学习如何进行环境配置、数据准备、模型训练、模型运行、模型保存以及本地模型使用。在开始之前，让我们先完成一些准备工作。</p><p>准备工作</p><h2 id="_1、访问-unsloth" tabindex="-1"><a class="header-anchor" href="#_1、访问-unsloth"><span>1、访问 Unsloth</span></a></h2><p>目前，最简单的方法是使用 Unsloth，它是一个微调模型的集成工具。通过 Unsloth 微调 Mistral、Gemma、Llama，速度提高 2-5 倍，内存减少 70%！</p>',12),X={href:"https://github.com/unslothai/unsloth",target:"_blank",rel:"noopener noreferrer"},O=s("p",null,[s("img",{src:m,alt:""})],-1),Y={href:"https://colab.research.google.com/drive/1pvzl7E2rdTF7LkDQZOTyl32_Vu9Zwe4N?usp=sharing",target:"_blank",rel:"noopener noreferrer"},J=n('<p>如果你是初学者，建议使用我修改过的 Colab 笔记。</p><p><img src="'+h+'" alt=""></p><h2 id="_2、创建-colab-笔记副本" tabindex="-1"><a class="header-anchor" href="#_2、创建-colab-笔记副本"><span>2、创建 Colab 笔记副本</span></a></h2><p>使用 Colab 的好处是标准化的环境，免去了很多问题。我们先将笔记复制为副本，这样它能保存到自己的 Google Drive 中。</p><p><img src="'+c+'" alt=""></p><p><img src="'+u+'" alt=""></p><h2 id="_3、连接-t4-gpu" tabindex="-1"><a class="header-anchor" href="#_3、连接-t4-gpu"><span>3、连接 T4 GPU</span></a></h2><p>你可以免费使用 Google 提供的 GPU 资源，选择连接 T4。当连接成功后，就可以开始了。</p><p><img src="'+_+'" alt=""></p><p>你也可以在弹框中选择 T4 GPU。</p><p><img src="'+d+'" alt=""></p><p>当链接成功后，你就准备就绪了。</p><p><img src="'+g+'" alt=""></p><h2 id="_4、连接-google-drive" tabindex="-1"><a class="header-anchor" href="#_4、连接-google-drive"><span>4、连接 Google Drive</span></a></h2><p>我们需要连接 Google Drive，以便将训练好的模型保存到云端。使用 Colab 非常简单，你基本只需依次点击运行每个代码块即可。</p><p><img src="'+b+'" alt=""></p><p>5、安装 Unsloth</p><p>点击运行，这段代码主要是安装 Unsloth 和模型训练相关的必要库。</p><p><img src="'+L+'" alt=""></p><p>展示执行时间表示已经执行过了。</p><p><img src="'+C+'" alt=""></p><h2 id="步入正题" tabindex="-1"><a class="header-anchor" href="#步入正题"><span>步入正题</span></a></h2><p>一切准备就绪，我们要进入正式流程了</p><h3 id="_1-选择预训练模型" tabindex="-1"><a class="header-anchor" href="#_1-选择预训练模型"><span>1. 选择预训练模型</span></a></h3><p>这一段代码主要用于选择我们要训练的模型，代码中已经帮我们选择好了&quot;unsloth/llama-3-8b-bnb-4bit&quot;。继续点击运行，等待模型下载完成。</p><p><img src="'+x+'" alt=""></p><p>点击之后，我们会看到它正在下载模型，需要等待它执行完毕。</p><p><img src="'+f+'" alt=""></p><h3 id="_2-配置-lora-参数" tabindex="-1"><a class="header-anchor" href="#_2-配置-lora-参数"><span>2. 配置 LoRA 参数</span></a></h3><p>我们的微调是通过 LoRA 实现的。LoRA（Low-Rank Adaptation of Large Language Models）是大语言模型的低阶适配器，用于在模型微调过程中只更新整个模型参数的一小部分，通常在 1%到 10%之间。</p><p>继续点击运行。</p><p><img src="'+v+`" alt=""></p><h3 id="_3-准备数据" tabindex="-1"><a class="header-anchor" href="#_3-准备数据"><span>3. 准备数据</span></a></h3><p>微调模型最重要的是数据。这里我们使用 yahma 的 Alpaca 数据集，它包含 52,000 条由 OpenAI 的 text-davinci-003 引擎生成的指令和演示数据。这些指令数据可用于对语言模型进行指令调优，使其更好地遵循指令。</p><p>Alpaca 的数据结构如下</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>&quot;instruction&quot;: &quot;描述原子的结构。&quot;,
&quot;input&quot;: &quot;&quot;,
&quot;output&quot;: &quot;原子是所有物质的基本组成部分，由三种类型的粒子组成：质子、中子和电子。原子的结构可以描述为中心有一个原子核，周围环绕着电子云。原子核由质子和中子组成。质子是带正电的粒子，中子是不带电荷的中性粒子……&quot;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>每条数据，结构由三部分组成：instruction (指令)、input(输入)和 output(输出)，我们可以根据这个格式准备自己的数据集。</p><p>instruction（指令）：这部分定义了要求 AI 执行的任务或问题。它是一条明确的指示，告诉 AI 需要做什么。例如，&quot;识别以下句子中的名词&quot;或&quot;我应该投资股票吗？&quot;。</p><p>input（输入）：这部分提供了执行指令所需的具体信息或上下文。在某些情况下，这个部分可能为空，表示指令本身已经包含了执行任务所需的所有信息。</p><p>output（输出）：这部分是 AI 根据给定的指令和输入生成的答案或结果。它是 AI 处理完输入信息后的响应或解决方案。</p><p>继续点击播放，执行代码。</p><p><img src="`+y+'" alt=""></p><h3 id="_4-训练模型" tabindex="-1"><a class="header-anchor" href="#_4-训练模型"><span>4. 训练模型</span></a></h3><p>现在让我们使用 Huggingface TRL 的 SFTTrainer 库来训练模型，我们设置 max_steps 最大步数为 60 步来加快训练速度，让我们继续无脑的点击播放：</p><p><img src="'+w+'" alt=""></p><p>然后，就可以开始正式训练模型了。</p><p><img src="'+E+'" alt=""></p><h3 id="_5-测试训练效果" tabindex="-1"><a class="header-anchor" href="#_5-测试训练效果"><span>5. 测试训练效果</span></a></h3><p>训练完成后，我们可以测试模型效果。这里我们先让它生成斐波那契数列（Fibonacci sequence）。</p><p><img src="'+G+'" alt=""></p><p>你也可以更改指令 instruction 和输入 input，测试你想要的内容。但是注意需要使用英文。</p><p>另外，我们还可以使用流格式，像使用 GPT 一样，一个个字地输出。</p><p><img src="'+k+'" alt=""></p><h3 id="_6-保存模型和加载模型" tabindex="-1"><a class="header-anchor" href="#_6-保存模型和加载模型"><span>6. 保存模型和加载模型</span></a></h3><p>目前，我们模型已经训练好了，我们可以将刚刚训练的 LoRA 保存下来。</p><p>6.1.保存和加载 LoRA 模型</p><p>点击运行，将 LoRA 模型保存到 Colab 的临时服务器中。</p><p><img src="'+q+'" alt=""></p><p>训练好的 LoRA 模型保存在 lora_model 文件夹中。</p><p><img src="'+T+'" alt=""></p><p>如果你想加载刚刚训练的 LoRA 模型进行测试，可以执行相应的代码。</p><p><img src="'+U+'" alt=""></p><p>6.2 保存为 GGUF 模型</p><p>目前较为常用的模型格式是 GGUF，我们可以使用 LM Studio 在本地加载使用。</p><p>这段代码可以将模型保存为不同的精度格式，建议使用 Q4_K，生成的体积比较小，只有 4GB。</p><p><img src="'+B+'" alt=""></p><p>生成的模型在这里，但是直接下载比较难。</p><p><img src="'+P+'" alt=""></p><p>我们可以执行这段代码，将生成的模型移动到 Google 云端硬盘中，这样下载更方便。</p><p><img src="'+A+'" alt=""></p><p>移动完成后，访问 Google 云端硬盘即可下载 GGUF 模型。</p><p>地址：https://drive.google.com/drive/my-drive</p><p><img src="'+D+'" alt=""></p><p>这样我们微调的整个过程就完成了。恭喜你！</p><h2 id="本地使用模型" tabindex="-1"><a class="header-anchor" href="#本地使用模型"><span>本地使用模型</span></a></h2><h3 id="_1-下载-lm-studio-的客户端" tabindex="-1"><a class="header-anchor" href="#_1-下载-lm-studio-的客户端"><span>1.下载 LM Studio 的客户端</span></a></h3>',76),Z={href:"https://lmstudio.ai",target:"_blank",rel:"noopener noreferrer"},j=n('<p><img src="'+M+'" alt=""></p><h3 id="_2-导入模型" tabindex="-1"><a class="header-anchor" href="#_2-导入模型"><span>2. 导入模型</span></a></h3><p>将 GGUF 文件放到 LM Studio 的模型文件夹中。打开保存模型的文件夹目录：models。</p><p><img src="'+R+'" alt=""></p><p>在指定路径中创建文件夹，目录结构为<code>llama3/model-unsloth/</code>。在 models 文件夹中新建一个文件夹 llama3，然后再创建一个模型文件夹 model-unsloth，将下载的模型放进去。</p><p><img src="'+F+'" alt=""></p><p>设置完成后，重启 LM Studio。</p><h3 id="_3-开始聊天" tabindex="-1"><a class="header-anchor" href="#_3-开始聊天"><span>3. 开始聊天</span></a></h3><p>选择模型后，就可以开始聊天了。</p><p><img src="'+I+'" alt=""></p><h2 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h2><p>本教程详细介绍了如何使用 Unsloth 和 Google Colab 环境对 Llama 3 进行微调。使用 Colab 基本上是无脑点击运行就好了。</p><p>经过这个教程，我们发现微调模型主要有三个核心环节：</p><p>数据准备，这一步决定了质量；</p><p>模型训练，这一步硬件资源决定了时间；</p><p>模型测试，因为我们初步体验，所以比较简略，后续可以进一步探讨。</p><p>通过本教程，即使是 AI 领域的新手也能够掌握大模型的微调技术。Unsloth 不仅降低了技术门槛，也为个人和小团队提供了强大的工具。</p><p>如果还有问题，可以查看我的 notebook 或者进群讨论。希望你能将这些知识应用于实际问题，解锁更多的可能性。</p>',18),z={href:"https://docs.qq.com/form/page/DU1FReEpXdkpKWHlO",target:"_blank",rel:"noopener noreferrer"},H=s("h3",{id:"参考资料",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#参考资料"},[s("span",null,"参考资料：")])],-1),K={href:"https://mp.weixin.qq.com/s/qcBddyN8srFB0MPh5shgtQ",target:"_blank",rel:"noopener noreferrer"},W={href:"https://mp.weixin.qq.com/s/VV1BUMQIMrb5LxQNusQsDg",target:"_blank",rel:"noopener noreferrer"};function $(ss,ts){const a=o("ExternalLinkIcon");return p(),i("div",null,[S,s("p",null,[s("a",V,[t("colab 版"),e(a)])]),N,s("p",null,[s("a",X,[t("访问 Unsloth 的 GitHub 地址"),e(a)]),t('，点击 "▶️Start on Colab" "即可打开 Colab 训练脚本。')]),O,s("p",null,[t("为了方便大家快速上手，我已经将其翻译成"),s("a",Y,[t("中文并简化"),e(a)])]),J,s("p",null,[s("a",Z,[t("访问"),e(a)]),t(" 下载 LM Studio 的客户端，它可以加载我们刚刚训练的模型。")]),j,s("p",null,[s("a",z,[t("模型训练的交流群申请"),e(a)])]),H,s("p",null,[s("a",K,[t("简版"),e(a)])]),s("p",null,[s("a",W,[t("colab版"),e(a)])])])}const es=l(Q,[["render",$],["__file","colab.html.vue"]]),ns=JSON.parse('{"path":"/posts/tutorial/start/colab.html","title":"Llama3 微调教程：超简单，人人都可以打造属于自己的 GPT！","lang":"en-US","frontmatter":{"description":"Llama3 微调教程：超简单，人人都可以打造属于自己的 GPT！ colab 版 作者：PM 熊叔 随着 Llama 3 的发布，国内各路英雄豪杰纷纷开启了炼丹之旅。Llama-3 8b 在惊人的 15 万亿令牌上训练，而 Llama-2 仅为 2 万亿。毋庸置疑，Llama 3 目前是开源大模型中能力最强的！其跑分成绩已经赶上了 GPT-4。 然而...","head":[["meta",{"property":"og:url","content":"https://www.Llama3-Chinese-Enthusiasts-Community.com/Llama3-Chinese-Enthusiasts-Community/posts/tutorial/start/colab.html"}],["meta",{"property":"og:site_name","content":"Llama3 中文爱好者社区"}],["meta",{"property":"og:title","content":"Llama3 微调教程：超简单，人人都可以打造属于自己的 GPT！"}],["meta",{"property":"og:description","content":"Llama3 微调教程：超简单，人人都可以打造属于自己的 GPT！ colab 版 作者：PM 熊叔 随着 Llama 3 的发布，国内各路英雄豪杰纷纷开启了炼丹之旅。Llama-3 8b 在惊人的 15 万亿令牌上训练，而 Llama-2 仅为 2 万亿。毋庸置疑，Llama 3 目前是开源大模型中能力最强的！其跑分成绩已经赶上了 GPT-4。 然而..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Llama3 微调教程：超简单，人人都可以打造属于自己的 GPT！\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[]}"]]},"headers":[{"level":2,"title":"1、访问 Unsloth","slug":"_1、访问-unsloth","link":"#_1、访问-unsloth","children":[]},{"level":2,"title":"2、创建 Colab 笔记副本","slug":"_2、创建-colab-笔记副本","link":"#_2、创建-colab-笔记副本","children":[]},{"level":2,"title":"3、连接 T4 GPU","slug":"_3、连接-t4-gpu","link":"#_3、连接-t4-gpu","children":[]},{"level":2,"title":"4、连接 Google Drive","slug":"_4、连接-google-drive","link":"#_4、连接-google-drive","children":[]},{"level":2,"title":"步入正题","slug":"步入正题","link":"#步入正题","children":[{"level":3,"title":"1. 选择预训练模型","slug":"_1-选择预训练模型","link":"#_1-选择预训练模型","children":[]},{"level":3,"title":"2. 配置 LoRA 参数","slug":"_2-配置-lora-参数","link":"#_2-配置-lora-参数","children":[]},{"level":3,"title":"3. 准备数据","slug":"_3-准备数据","link":"#_3-准备数据","children":[]},{"level":3,"title":"4. 训练模型","slug":"_4-训练模型","link":"#_4-训练模型","children":[]},{"level":3,"title":"5. 测试训练效果","slug":"_5-测试训练效果","link":"#_5-测试训练效果","children":[]},{"level":3,"title":"6. 保存模型和加载模型","slug":"_6-保存模型和加载模型","link":"#_6-保存模型和加载模型","children":[]}]},{"level":2,"title":"本地使用模型","slug":"本地使用模型","link":"#本地使用模型","children":[{"level":3,"title":"1.下载 LM Studio 的客户端","slug":"_1-下载-lm-studio-的客户端","link":"#_1-下载-lm-studio-的客户端","children":[]},{"level":3,"title":"2. 导入模型","slug":"_2-导入模型","link":"#_2-导入模型","children":[]},{"level":3,"title":"3. 开始聊天","slug":"_3-开始聊天","link":"#_3-开始聊天","children":[]}]},{"level":2,"title":"总结","slug":"总结","link":"#总结","children":[{"level":3,"title":"参考资料：","slug":"参考资料","link":"#参考资料","children":[]}]}],"git":{"updatedTime":null,"contributors":[]},"filePathRelative":"posts/tutorial/start/colab.md","autoDesc":true,"excerpt":"\\n<p><a href=\\"https://mp.weixin.qq.com/s/VV1BUMQIMrb5LxQNusQsDg\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">colab 版</a></p>\\n<p>作者：PM 熊叔</p>\\n<p>随着 Llama 3 的发布，国内各路英雄豪杰纷纷开启了炼丹之旅。Llama-3 8b 在惊人的 15 万亿令牌上训练，而 Llama-2 仅为 2 万亿。毋庸置疑，Llama 3 目前是开源大模型中能力最强的！其跑分成绩已经赶上了 GPT-4。</p>\\n<p></p>\\n<p>然而，Llama 的优势不仅限于此。作为开源大模型，每个人都可以对其进行定制，这意味着相比 GPT，它具有更强的定制性和安全性。Llama 可应用于针对 B 端企业的自然语言处理、机器翻译、文本生成、问答系统、聊天机器人等场景。</p>"}');export{es as comp,ns as data};
